# Anirudh Ramchandran Portfolio

## Project 1 : [Stock Price Forecasting and Clustering based on Trading pattern](https://github.com/anirudhsuresh/Stock-Market)              
* Performed statistical and data anlysis for FAANG and tesla stocks in R to gain deeper understanding of thier behaviour during Coronavirus. 
*	Designed models using K-means and Gaussian Mixture Models to cluster 51 random companies based on thier trading patterns .The resulting clusters showed resemblances in sectors, market cap, or price-to-earnings ratios.
*	Programmed time series models using Linear Regression, Prophet to forecast adjusted closing prices for any given stock based on its historical data. 
* *Languages and Packages used* :R,Python,Prophet,K-means,GMM,plotly,seaborn


## Project 2 :[Classifying which NYC taxi ride would be getting Tips ](https://github.com/anirudhsuresh/Green_taxi_Tip_Classifier)
*	Performed exploratory data analysis in R and was able to show how various factors impacted tipping in an NYC taxi ride 
*	Designed a classifier model that could tell if a Taxi driver would get tips based on factors like the pickup/drop location and hours. Model was able to get an accuracy of around 88%.

## Project 3: [Developer Name Disambiguation (de-aliasing) on Apache Software Foundation(ASF)](https://github.com/anirudhsuresh/Final-Project-for-ECS-189L---Developer-Name-Disambiguation)
*	Scraped the 330 projects present in the ASF using BeautifulSoup4, then performed the necessary pre-processing steps to create a clean data set.
*	Designed clustering models: to correctly find full author name given only project name, finding developers’ hidden email id, and clustering similar author/developer names. Models showed an accuracy of around 90% when assessed.

## Project 4: [Solving Adaptive 2048 using Deep Q learning](https://github.com/anirudhsuresh/Deep-Q-learning-on-adaptive-2048-Game)

*	Modified the popular sliding block game ‘2048’ to hinder the player from using already known strategies for winning the game 
*	Implemented an intelligent Q learning agent with a 5-layer end-to-end, Deep learning-based neural network to learn game control policies, which enabled the agent to get scores of ‘512.’ 



